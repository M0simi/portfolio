# core/ai_service.py
import os
from io import BytesIO
import google.generativeai as genai
from django.core.files.storage import default_storage
from PyPDF2 import PdfReader
from .models import KnowledgeBase

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
MODEL = os.getenv("GEMINI_MODEL", "gemini-1.5-flash-latest").strip()
MAX_CHARS = 60000


SAFETY_OFF = [
    {"category": "HARM_CATEGORY_HATE_SPEECH",     "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HARASSMENT",      "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUAL_CONTENT",  "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT","threshold": "BLOCK_NONE"},
]

def _load_kb_text():
    kb = KnowledgeBase.objects.order_by("-id").first()
    if not kb:
        return ""
    txt = (getattr(kb, "content", "") or "").strip()
    if txt:
        return txt[:MAX_CHARS]
    f = getattr(kb, "file", None)
    if not f:
        return ""
    try:
        with default_storage.open(f.name, "rb") as fp:
            data = fp.read()
    except Exception as e:
        return f"[KB-READ-ERROR] {e}"
    try:
        reader = PdfReader(BytesIO(data))
        parts = []
        acc = 0
        for p in reader.pages:
            t = (p.extract_text() or "")
            if t:
                parts.append(t)
                acc += len(t)
                if acc >= MAX_CHARS:
                    break
        return ("\n".join(parts)).strip()
    except Exception as e:
        return f"[KB-PARSE-ERROR] {e}"

def _clean(ans: str) -> str:
    if not ans:
        return ""
    for bad in ["ุญุณุจ ุงูููู", "ููููุง ูููุณุชูุฏ", "PDF", "ุงูููู:"]:
        ans = ans.replace(bad, "")
    return ans.strip()

def ask_gemini(user_prompt: str) -> str:
    if not GEMINI_API_KEY:
        return "โ ููููุฏ ูุชุบูุฑ ุงูุจูุฆุฉ GEMINI_API_KEY."
    genai.configure(api_key=GEMINI_API_KEY)

    kb_text = _load_kb_text()
    kb_note = ""
    if kb_text.startswith("[KB-READ-ERROR]") or kb_text.startswith("[KB-PARSE-ERROR]"):
        kb_note = kb_text
        kb_text = ""

    system_msg = (
        "ุฃูุช UniBot ๐ โ ูุณุงุนุฏ ุฌุงูุนู ุนุฑุจู ูุตูุญ. "
        "ุฃุฌุจ ุฅุฌุงุจุฉ ูุนูููุงุชูุฉ ููุญุงูุฏุฉ ููุชุตุฑุฉ ุนูู ููุงุฆุญ ุงูุฌุงูุนุฉ ููุท. "
        "ุฅุฐุง ูู ุชุฌุฏ ุงูุฅุฌุงุจุฉ ูู ุงููุต ุงููุฑููุ ูู: ยซุนุฐุฑูุงุ ุณุคุงูู ุบูุฑ ููุฌูุฏ ูู ุงูููู ุงูุญุงูู.ยป "
        "ุชุฌูุจ ุฃู ูุญุชูู ุญุณุงุณ ุฃู ุฎุงุฑุฌ ุณูุงู ุงูููุงุฆุญ."
    )

    prompt = f"""{system_msg}

--- ููุชุทู ูู ุงูุฏููู/ุงูุฃุณุฆูุฉ ---
{kb_text if kb_text else "ูุง ูุชููุฑ ูุญุชูู ูุนุฑูุฉ ุญุงููุงู."}

--- ุณุคุงู ุงููุณุชุฎุฏู ---
{user_prompt}
"""

    if kb_note:
        prompt += f"\n[ููุงุญุธุฉ ุชูููุฉ]: {kb_note}\n"

   
    model = genai.GenerativeModel(
        MODEL,
        safety_settings=SAFETY_OFF,
        generation_config={"temperature": 0.2, "max_output_tokens": 2048},
    )

    try:
        resp = model.generate_content(prompt)
        # ูู ุงูุญุธุฑ ุงูุฑุฏ (SAFETY) ุฃู ุงูุชูู ุจูุง ูุตุ ูุฌุฑุจ ุฅุนุงุฏุฉ ุงูุตูุงุบุฉ
        text = getattr(resp, "text", "") or ""
        if not text:
            # ุฑูุชุฑุงู ุจุตูุงุบุฉ ุฃูุซุฑ โุขููุฉโ
            retry = model.generate_content(
                f"ุฃุนุฏ ุตูุงุบุฉ ุฅุฌุงุจุฉ ูุตูุฑุฉ ููุนูููุงุชูุฉ ููุณุคุงู ุงูุชุงูู ุจุฏูู ุฃู ูุญุชูู ุญุณุงุณ:"
                f"\n\nุงููุต ุงููุณููุญ ุงูุงุนุชูุงุฏ ุนููู:\n{kb_text[:4000]}\n\nุงูุณุคุงู:\n{user_prompt}"
            )
            text = getattr(retry, "text", "") or ""

        text = _clean(text)
        if not text:
            text = "ุนุฐุฑูุงุ ุณุคุงูู ุบูุฑ ููุฌูุฏ ูู ุงูููู ุงูุญุงูู."
        return text

    except Exception as e:
        # ูุฑุฌูุน ุงูุณุจุจ ูุตูุง ุนุดุงู ุชุดููู ูู ุงููุงุฌูุฉ
        return f"โ๏ธ ุญุฏุซ ุฎุทุฃ ูู ุฎุฏูุฉ ุงูุฐูุงุก: {e}"
